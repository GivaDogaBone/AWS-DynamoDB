# .github/workflows/deploy.yml
name: Deploy Venues API

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Allows manual triggering

jobs:
  test:
    name: Test Application
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        pip install pytest pytest-cov

    - name: Run tests
      run: |
        pytest --cov=./ --cov-report=xml

    - name: Upload coverage report
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

  terraform:
    name: Terraform Infrastructure
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Terraform Init
      run: terraform init

    - name: Terraform Format
      run: terraform fmt -check

    - name: Check if table exists and import
      id: check_table
      run: |
        # Check if the DynamoDB table already exists in AWS
        if aws dynamodb describe-table --table-name venues &>/dev/null; then
          echo "DynamoDB table 'venues' already exists"
          echo "table_exists=true" >> $GITHUB_OUTPUT
          
          # Check if the table is already in the Terraform state
          if ! terraform state list | grep -q aws_dynamodb_table.venues; then
            echo "Importing existing table into Terraform state"
            terraform import aws_dynamodb_table.venues venues || echo "Import failed, but continuing"
          else
            echo "Table already in Terraform state"
          fi
        else
          echo "table_exists=false" >> $GITHUB_OUTPUT
          echo "Table doesn't exist yet, will be created by Terraform"
        fi

    - name: Terraform Plan
      run: terraform plan -var-file="terraform.tfvars"

    - name: Terraform Apply
      if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
      run: |
        # Apply with auto-approve
        terraform apply -var-file="terraform.tfvars" -auto-approve || true
        
        # Verify that the apply either succeeded or failed due to "Table already exists"
        status=$?
        if [ $status -ne 0 ]; then
          # Check if the error was because the table already exists
          if aws dynamodb describe-table --table-name venues &>/dev/null; then
            echo "Table already exists and is available. Proceeding with deployment."
            
            # Force refresh state
            terraform refresh -var-file="terraform.tfvars"
            
            # Consider deployment successful
            exit 0
          else
            echo "Terraform apply failed for reasons other than 'Table already exists'"
            exit 1
          fi
        fi

  deploy_app:
    name: Deploy Application
    runs-on: ubuntu-latest
    needs: terraform
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        pip install aws-cdk-lib

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Build and package application
      run: |
        mkdir -p dist
        cp -r *.py dist/
        pip install -r requirements.txt -t dist/
        cd dist && zip -r ../lambda_function.zip .

    - name: Check Lambda permissions
      run: |
        echo "Checking Lambda function permissions..."
        
        # Get the role name from the Lambda function
        LAMBDA_NAME="venues-api"
        ROLE_ARN=$(aws lambda get-function --function-name $LAMBDA_NAME --query 'Configuration.Role' --output text)
        ROLE_NAME=$(echo $ROLE_ARN | awk -F '/' '{print $NF}')
        
        echo "Lambda function $LAMBDA_NAME uses role $ROLE_NAME (ARN: $ROLE_ARN)"
        
        # Check the role's policies
        echo "Checking role policies..."
        POLICIES=$(aws iam list-attached-role-policies --role-name $ROLE_NAME --query 'AttachedPolicies[].PolicyName' --output text)
        echo "Attached policies: $POLICIES"
        
        # Check for DynamoDB access
        echo "Checking for DynamoDB access..."
        if echo "$POLICIES" | grep -q "DynamoDB"; then
          echo "✅ DynamoDB policy is attached"
        else
          echo "⚠️ WARNING: No DynamoDB policy found! Attaching AmazonDynamoDBFullAccess policy..."
          aws iam attach-role-policy --role-name $ROLE_NAME --policy-arn arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess
          echo "✅ DynamoDB policy attached"
        fi
        
        # Check for CloudWatch Logs access
        echo "Checking for CloudWatch Logs access..."
        if echo "$POLICIES" | grep -q "CloudWatch"; then
          echo "✅ CloudWatch Logs policy is attached"
        else
          echo "⚠️ WARNING: No CloudWatch Logs policy found! Attaching CloudWatchLogsFullAccess policy..."
          aws iam attach-role-policy --role-name $ROLE_NAME --policy-arn arn:aws:iam::aws:policy/CloudWatchLogsFullAccess
          echo "✅ CloudWatch Logs policy attached"
        fi
        
        # Check Lambda configuration
        echo "Checking Lambda configuration..."
        CONFIG=$(aws lambda get-function-configuration --function-name $LAMBDA_NAME)
        TIMEOUT=$(echo "$CONFIG" | jq -r '.Timeout')
        MEMORY=$(echo "$CONFIG" | jq -r '.MemorySize')
        HANDLER=$(echo "$CONFIG" | jq -r '.Handler')
        
        echo "Current configuration:"
        echo "- Timeout: $TIMEOUT seconds"
        echo "- Memory: $MEMORY MB"
        echo "- Handler: $HANDLER"
        
        # Wait for any ongoing Lambda updates to complete
        echo "Waiting for any ongoing Lambda updates to complete..."
        aws lambda wait function-updated-v2 --function-name $LAMBDA_NAME
        
        # Update Lambda config if needed
        if [ "$TIMEOUT" -lt 30 ] || [ "$MEMORY" -lt 256 ] || [ "$HANDLER" != "lambda_handler.lambda_entrypoint" ]; then
          echo "Updating Lambda configuration..."
          aws lambda update-function-configuration \
            --function-name $LAMBDA_NAME \
            --timeout 30 \
            --memory-size 256 \
            --handler lambda_handler.lambda_entrypoint
          
          echo "Waiting for Lambda configuration update to complete..."
          aws lambda wait function-updated-v2 --function-name $LAMBDA_NAME
        fi
        
        echo "Lambda permissions check completed"

    - name: Deploy to AWS Lambda
      run: |
        # Update the Lambda function (or create if not exists)
        if aws lambda get-function --function-name venues-api 2>/dev/null; then
          echo "Lambda function exists, updating code..."
          aws lambda update-function-code \
            --function-name venues-api \
            --zip-file fileb://lambda_function.zip
          
          # Wait for Lambda to finish updating before proceeding
          echo "Waiting for Lambda code update to complete..."
          aws lambda wait function-updated-v2 --function-name venues-api
          
          echo "Lambda code update complete, now updating configuration..."
          # Update the Lambda configuration to use the function with logging
          aws lambda update-function-configuration \
            --function-name venues-api \
            --handler lambda_handler.lambda_entrypoint \
            --timeout 30 \
            --memory-size 256 \
            --environment "Variables={CUSTOM_AWS_REGION=${{ secrets.AWS_REGION }},DYNAMODB_TABLE_NAME=venues}"
        else
          echo "Lambda function does not exist, creating new function..."
          aws lambda create-function \
            --function-name venues-api \
            --runtime python3.9 \
            --role ${{ secrets.LAMBDA_EXECUTION_ROLE }} \
            --handler lambda_handler.lambda_entrypoint \
            --timeout 30 \
            --memory-size 256 \
            --zip-file fileb://lambda_function.zip \
            --environment "Variables={CUSTOM_AWS_REGION=${{ secrets.AWS_REGION }},DYNAMODB_TABLE_NAME=venues}"
        fi
        
        # Wait for Lambda to finish updating before proceeding
        echo "Waiting for Lambda updates to complete..."
        aws lambda wait function-updated-v2 --function-name venues-api
        
        echo "Lambda deployment complete."

    - name: Generate OpenAPI definition
      run: |
        echo "Generating OpenAPI definition for API Gateway..."
        
        # First ensure we have all dependencies
        pip install fastapi pydantic

        # Create a temporary Python script to extract the OpenAPI schema
        cat > generate_openapi.py << 'EOF'
import json
import sys
from main import app

# Get the OpenAPI JSON
openapi_schema = app.openapi()

# Save it to a file
with open("openapi.json", "w") as f:
    json.dump(openapi_schema, f, indent=2)

print("OpenAPI schema exported to openapi.json")
EOF

        # Run the script to generate the OpenAPI schema
        python generate_openapi.py
        
        # Get AWS account ID
        ACCOUNT_ID=$(aws sts get-caller-identity --query "Account" --output text)
        
        # Create a temporary Python script to add API Gateway extensions
        cat > add_extensions.py << 'EOF'
import json
import sys
import os

# Read environment variables
region = os.environ.get('AWS_REGION')
account_id = os.environ.get('ACCOUNT_ID')

with open("openapi.json", "r") as f:
    schema = json.load(f)

# Add API Gateway integrations
for path in schema["paths"]:
    for method in schema["paths"][path]:
        if method.lower() not in ["get", "post", "put", "delete", "patch", "options", "head"]:
            continue

        schema["paths"][path][method]["x-amazon-apigateway-integration"] = {
            "uri": f"arn:aws:apigateway:{region}:lambda:path/2015-03-31/functions/arn:aws:lambda:{region}:{account_id}:function:venues-api/invocations",
            "passthroughBehavior": "when_no_match",
            "httpMethod": "POST",
            "type": "aws_proxy"
        }

# Add API Gateway binary media types if needed
schema["x-amazon-apigateway-binary-media-types"] = ["application/json"]

# Add CORS configuration
for path in schema["paths"]:
    # Add OPTIONS method with CORS support for each path if it doesn't exist
    if "options" not in schema["paths"][path]:
        schema["paths"][path]["options"] = {
            "summary": "CORS support",
            "description": "Enable CORS by returning correct headers",
            "tags": ["CORS"],
            "responses": {
                "200": {
                    "description": "CORS headers returned",
                    "headers": {
                        "Access-Control-Allow-Origin": {
                            "schema": {"type": "string"}
                        },
                        "Access-Control-Allow-Methods": {
                            "schema": {"type": "string"}
                        },
                        "Access-Control-Allow-Headers": {
                            "schema": {"type": "string"}
                        }
                    },
                    "content": {}
                }
            },
            "x-amazon-apigateway-integration": {
                "type": "mock",
                "requestTemplates": {
                    "application/json": "{'statusCode': 200}"
                },
                "responses": {
                    "default": {
                        "statusCode": "200",
                        "responseParameters": {
                            "method.response.header.Access-Control-Allow-Origin": "'*'",
                            "method.response.header.Access-Control-Allow-Methods": "'GET,POST,PUT,DELETE,OPTIONS'",
                            "method.response.header.Access-Control-Allow-Headers": "'Content-Type,Authorization,X-Amz-Date,X-Api-Key'"
                        },
                        "responseTemplates": {
                            "application/json": "{}"
                        }
                    }
                }
            }
        }

    # For each method (except OPTIONS), add CORS headers to response
    for method in schema["paths"][path]:
        if method.lower() != "options":
            for response in schema["paths"][path][method].get("responses", {}).values():
                if "headers" not in response:
                    response["headers"] = {}

                response["headers"]["Access-Control-Allow-Origin"] = {"schema": {"type": "string"}}

# Write the updated schema
with open("openapi-with-extensions.json", "w") as f:
    json.dump(schema, f, indent=2)
EOF

        # Export environment variables and run the script
        export AWS_REGION=${{ secrets.AWS_REGION }}
        export ACCOUNT_ID=$ACCOUNT_ID
        python add_extensions.py
        
        echo "OpenAPI definition with API Gateway extensions generated"

    - name: Deploy API using OpenAPI definition
      run: |
        # Get AWS account ID
        ACCOUNT_ID=$(aws sts get-caller-identity --query "Account" --output text)
        
        # Check if API Gateway exists
        API_ID=$(aws apigateway get-rest-apis --query "items[?name=='venues-api'].id" --output text)
        
        if [ -z "$API_ID" ]; then
          echo "Creating new API Gateway from OpenAPI definition..."
          API_ID=$(aws apigateway import-rest-api \
            --body file://openapi-with-extensions.json \
            --name "venues-api" \
            --endpoint-configuration "{ \"types\": [\"REGIONAL\"] }" \
            --query 'id' --output text)
          
          echo "Created new API Gateway with ID: $API_ID"
        else
          echo "Updating existing API Gateway with OpenAPI definition..."
          aws apigateway put-rest-api \
            --rest-api-id $API_ID \
            --body file://openapi-with-extensions.json \
            --mode overwrite
        fi
        
        # Create deployment
        aws apigateway create-deployment \
          --rest-api-id $API_ID \
          --stage-name prod
        
        # Add Lambda permissions
        echo "Adding Lambda permissions for API Gateway..."
        aws lambda add-permission \
          --function-name venues-api \
          --statement-id apigateway-invoke-all \
          --action lambda:InvokeFunction \
          --principal apigateway.amazonaws.com \
          --source-arn "arn:aws:execute-api:${{ secrets.AWS_REGION }}:$ACCOUNT_ID:$API_ID/*/*" || true
        
        # Output API URLs
        echo "API Gateway deployment completed."
        echo "API URL: https://$API_ID.execute-api.${{ secrets.AWS_REGION }}.amazonaws.com/prod"
        echo "Swagger UI: https://$API_ID.execute-api.${{ secrets.AWS_REGION }}.amazonaws.com/prod/docs"
        
        # Save API URL for later use
        echo "https://$API_ID.execute-api.${{ secrets.AWS_REGION }}.amazonaws.com/prod" > api_url.txt
